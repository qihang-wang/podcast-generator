"""
å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
ä½¿ç”¨ APScheduler å®ç°åå°å®šæ—¶ä»»åŠ¡

ä»»åŠ¡åˆ—è¡¨ï¼ˆæ¯å¤©å‡Œæ™¨0ç‚¹é¡ºåºæ‰§è¡Œï¼‰ï¼š
1. æ¸…ç†å‰å¤©çš„æ•°æ®
2. å¼ºåˆ¶åˆ·æ–°æ˜¨å¤©çš„æ•°æ®ï¼ˆå…ˆæ¸…ç†åé‡æ–°è·å–ï¼‰
"""

import logging
import os
import asyncio
from datetime import datetime, timedelta
from contextlib import asynccontextmanager

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger

# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
scheduler = AsyncIOScheduler()

# é¢„çƒ­çš„å›½å®¶ä»£ç åˆ—è¡¨ï¼ˆå¯é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®ï¼‰
DEFAULT_PREHEAT_COUNTRIES = ["CH", "US", "UK", "JP", "DE", "FR", "IN", "BR", "AU", "CA"]


def refresh_yesterday_data():
    """
    å¼ºåˆ¶åˆ·æ–°æ˜¨å¤©çš„æ•°æ®ï¼ˆå…ˆæ¸…ç†åé‡æ–°è·å–ï¼‰
    
    é…ç½®ç¯å¢ƒå˜é‡ï¼š
    - PREHEAT_COUNTRIES: é¢„çƒ­çš„å›½å®¶ä»£ç ï¼Œé€—å·åˆ†éš”ï¼ˆé»˜è®¤10ä¸ªå›½å®¶ï¼‰
    """
    try:
        from podcast_generator.database import ArticleRepository
        from podcast_generator.api.routes.articles_helpers import fetch_day_data
        
        repo = ArticleRepository()
        
        if not repo.is_available():
            logging.warning("âš ï¸ æ•°æ®åº“ä¸å¯ç”¨ï¼Œè·³è¿‡åˆ·æ–°ä»»åŠ¡")
            return
        
        # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
        countries_str = os.getenv("PREHEAT_COUNTRIES", ",".join(DEFAULT_PREHEAT_COUNTRIES))
        countries = [c.strip().upper() for c in countries_str.split(",") if c.strip()]
        
        # æ˜¨å¤©çš„æ—¥æœŸ
        yesterday = (datetime.now() - timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
        yesterday_str = yesterday.strftime("%Y-%m-%d")
        
        logging.info(f"ï¿½ [å®šæ—¶ä»»åŠ¡] å¼ºåˆ¶åˆ·æ–°æ˜¨å¤©æ•°æ®: å›½å®¶={countries}, æ—¥æœŸ={yesterday_str}")
        
        total_refreshed = 0
        for country in countries:
            # 1. å…ˆæ¸…ç†æ˜¨å¤©è¯¥å›½å®¶çš„æ•°æ®
            deleted = repo.cleanup_articles_by_date(yesterday, country)
            logging.info(f"   ğŸ§¹ {country}: æ¸…ç†äº† {deleted} æ¡æ—§æ•°æ®")
            
            # 2. é‡æ–°è·å–ï¼ˆä¸ä½¿ç”¨å¸¦é”ç‰ˆæœ¬ï¼Œå› ä¸ºè¦å¼ºåˆ¶åˆ·æ–°ï¼‰
            logging.info(f"   ğŸ“¥ {country}: é‡æ–°è·å–æ•°æ®...")
            fetch_day_data(country, yesterday)
            total_refreshed += 1
        
        logging.info(f"âœ… [å®šæ—¶ä»»åŠ¡] åˆ·æ–°å®Œæˆï¼å·²åˆ·æ–° {total_refreshed} ä¸ªå›½å®¶çš„æ•°æ®")
            
    except Exception as e:
        logging.error(f"âŒ [å®šæ—¶ä»»åŠ¡] åˆ·æ–°å¤±è´¥: {e}")


def cleanup_day_before_yesterday():
    """
    æ¸…ç†å‰å¤©çš„æ•°æ®
    
    æ¯å¤©0ç‚¹æ‰§è¡Œï¼Œåªä¿ç•™ä»Šå¤©å’Œæ˜¨å¤©çš„æ•°æ®
    """
    try:
        from podcast_generator.database import ArticleRepository
        
        repo = ArticleRepository()
        
        if not repo.is_available():
            logging.warning("âš ï¸ æ•°æ®åº“ä¸å¯ç”¨ï¼Œè·³è¿‡æ¸…ç†ä»»åŠ¡")
            return
        
        # å‰å¤©çš„æ—¥æœŸ
        day_before_yesterday = (datetime.now() - timedelta(days=2)).replace(hour=0, minute=0, second=0, microsecond=0)
        date_str = day_before_yesterday.strftime("%Y-%m-%d")
        
        logging.info(f"ğŸ§¹ [å®šæ—¶ä»»åŠ¡] å¼€å§‹æ¸…ç†å‰å¤© ({date_str}) çš„æ•°æ®...")
        
        # è·å–æ¸…ç†å‰çš„ç»Ÿè®¡
        stats_before = repo.get_storage_stats()
        
        # æ‰§è¡Œæ¸…ç†ï¼ˆä¸æŒ‡å®šå›½å®¶ï¼Œæ¸…ç†æ‰€æœ‰å›½å®¶çš„å‰å¤©æ•°æ®ï¼‰
        deleted = repo.cleanup_articles_by_date(day_before_yesterday)
        
        # è·å–æ¸…ç†åçš„ç»Ÿè®¡
        stats_after = repo.get_storage_stats()
        
        logging.info(
            f"âœ… [å®šæ—¶ä»»åŠ¡] æ¸…ç†å®Œæˆï¼\n"
            f"   åˆ é™¤: {deleted} æ¡\n"
            f"   å‰©ä½™: {stats_after['total_articles']} æ¡\n"
            f"   å­˜å‚¨: {stats_after['estimated_size_mb']:.2f} MB ({stats_after['usage_percent']:.1f}%)"
        )
        
        if stats_after['warning']:
            logging.warning(stats_after['warning'])
            
    except Exception as e:
        logging.error(f"âŒ [å®šæ—¶ä»»åŠ¡] æ¸…ç†å¤±è´¥: {e}")


def daily_maintenance():
    """
    æ¯æ—¥ç»´æŠ¤ä»»åŠ¡ï¼ˆå‡Œæ™¨0ç‚¹æ‰§è¡Œï¼‰
    
    æ‰§è¡Œé¡ºåºï¼š
    1. æ¸…ç†å‰å¤©çš„æ•°æ®
    2. å¼ºåˆ¶åˆ·æ–°æ˜¨å¤©çš„æ•°æ®ï¼ˆå…ˆæ¸…ç†åé‡æ–°è·å–ï¼‰
    """
    logging.info("ğŸŒ™ [å®šæ—¶ä»»åŠ¡] å¼€å§‹æ¯æ—¥ç»´æŠ¤...")
    
    # 1. æ¸…ç†å‰å¤©çš„æ•°æ®
    cleanup_day_before_yesterday()
    
    # 2. å¼ºåˆ¶åˆ·æ–°æ˜¨å¤©çš„æ•°æ®
    refresh_yesterday_data()
    
    logging.info("ğŸŒ… [å®šæ—¶ä»»åŠ¡] æ¯æ—¥ç»´æŠ¤å®Œæˆï¼")


def setup_scheduler():
    """
    é…ç½®å®šæ—¶ä»»åŠ¡
    
    ç¯å¢ƒå˜é‡é…ç½®ï¼š
    - MAINTENANCE_HOUR: æ¯æ—¥ç»´æŠ¤ä»»åŠ¡æ‰§è¡Œçš„å°æ—¶ï¼ˆé»˜è®¤ 0ï¼Œå³å‡Œæ™¨0ç‚¹ï¼‰
    - MAINTENANCE_MINUTE: æ¯æ—¥ç»´æŠ¤ä»»åŠ¡æ‰§è¡Œçš„åˆ†é’Ÿï¼ˆé»˜è®¤ 0ï¼‰
    - PREHEAT_COUNTRIES: é¢„çƒ­çš„å›½å®¶ä»£ç ï¼ˆé»˜è®¤ 10 ä¸ªå¸¸è§å›½å®¶ï¼‰
    """
    hour = int(os.getenv("MAINTENANCE_HOUR", "1"))
    minute = int(os.getenv("MAINTENANCE_MINUTE", "0"))
    
    scheduler.add_job(
        daily_maintenance,
        CronTrigger(hour=hour, minute=minute),
        id="daily_maintenance",
        name="æ¯æ—¥ç»´æŠ¤ï¼ˆæ¸…ç†+åˆ·æ–°ï¼‰",
        replace_existing=True
    )
    
    logging.info(f"ğŸ“… å®šæ—¶ä»»åŠ¡å·²é…ç½®: æ¯å¤© {hour:02d}:{minute:02d} æ‰§è¡Œæ¯æ—¥ç»´æŠ¤")


def start_scheduler():
    """å¯åŠ¨è°ƒåº¦å™¨"""
    if not scheduler.running:
        setup_scheduler()
        scheduler.start()
        logging.info("âœ… å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")


def stop_scheduler():
    """åœæ­¢è°ƒåº¦å™¨"""
    if scheduler.running:
        scheduler.shutdown()
        logging.info("â¹ï¸ å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²åœæ­¢")


@asynccontextmanager
async def lifespan_scheduler(app):
    """FastAPI lifespan ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    start_scheduler()
    yield
    stop_scheduler()
