"""
æ–°é—»åˆå¹¶æ¨¡å—
ç”¨äºåˆå¹¶æ ‡é¢˜ç›¸ä¼¼çš„é‡å¤æ–°é—»è®°å½•ï¼Œæ•´åˆå¤šæ¥æºä¿¡æ¯
"""

import re
from typing import List, Dict, Any


def normalize_title(title: str) -> str:
    """
    æ ‡é¢˜å½’ä¸€åŒ–å¤„ç†ï¼Œç”¨äºç›¸ä¼¼åº¦æ¯”è¾ƒ
    
    - è½¬æ¢ä¸ºå°å†™
    - ç§»é™¤æ ‡ç‚¹ç¬¦å·
    - ç§»é™¤æ—¥æœŸæ•°å­—ï¼ˆå¦‚ 2025 12 14ï¼‰
    - ä¿ç•™æ ¸å¿ƒå…³é”®è¯
    """
    if not title:
        return ""
    
    normalized = title.lower()
    
    # ç§»é™¤æ—¥æœŸæ ¼å¼ (å¦‚ 2025 12 14, 2025-12-14)
    normalized = re.sub(r'\b20\d{2}[\s\-/]?\d{1,2}[\s\-/]?\d{1,2}\b', '', normalized)
    
    # ç§»é™¤æ ‡ç‚¹ç¬¦å·
    normalized = re.sub(r'[^\w\s]', ' ', normalized)
    
    # åˆå¹¶å¤šä¸ªç©ºæ ¼
    normalized = ' '.join(normalized.split())
    
    return normalized.strip()


def calculate_title_similarity(title1: str, title2: str) -> float:
    """
    è®¡ç®—ä¸¤ä¸ªæ ‡é¢˜çš„ç›¸ä¼¼åº¦
    
    ä½¿ç”¨ Jaccard ç³»æ•°è®¡ç®—è¯é›†åˆçš„ç›¸ä¼¼åº¦
    è¿”å› 0.0-1.0 ä¹‹é—´çš„ç›¸ä¼¼åº¦åˆ†æ•°
    """
    if not title1 or not title2:
        return 0.0
    
    # å½’ä¸€åŒ–æ ‡é¢˜
    norm1 = normalize_title(title1)
    norm2 = normalize_title(title2)
    
    if not norm1 or not norm2:
        return 0.0
    
    # åˆ†è¯
    words1 = set(norm1.split())
    words2 = set(norm2.split())
    
    # è¿‡æ»¤åœç”¨è¯
    stopwords = {'the', 'a', 'an', 'in', 'on', 'at', 'to', 'for', 'of', 'and', 'or', 'is', 'are', 'was', 'were', 'from'}
    words1 = words1 - stopwords
    words2 = words2 - stopwords
    
    if not words1 or not words2:
        return 0.0
    
    # Jaccard ç›¸ä¼¼åº¦
    intersection = len(words1 & words2)
    union = len(words1 | words2)
    
    return intersection / union if union > 0 else 0.0


def merge_two_records(primary: Dict[str, Any], secondary: Dict[str, Any]) -> Dict[str, Any]:
    """
    åˆå¹¶ä¸¤æ¡ç›¸å…³æ–°é—»è®°å½•
    
    Args:
        primary: ä¸»è®°å½•ï¼ˆä¿ç•™æ ‡é¢˜å’ŒåŸºæœ¬ä¿¡æ¯ï¼‰
        secondary: æ¬¡è¦è®°å½•ï¼ˆåˆå¹¶å…¶ç‹¬ç‰¹å†…å®¹ï¼‰
    
    Returns:
        åˆå¹¶åçš„è®°å½•
    """
    merged = primary.copy()
    
    # åˆå¹¶æ¥æºä¿¡æ¯
    sources = [primary.get('Source_Name', '')]
    if secondary.get('Source_Name') and secondary['Source_Name'] not in sources:
        sources.append(secondary['Source_Name'])
    merged['Source_Name'] = ' | '.join(filter(None, sources))
    
    # åˆå¹¶æ¥æºURL
    urls = [primary.get('Source_URL', '')]
    if secondary.get('Source_URL') and secondary['Source_URL'] not in urls:
        urls.append(secondary['Source_URL'])
    merged['Source_URL'] = ' ; '.join(filter(None, urls))
    
    # åˆå¹¶å¼•è¯­ï¼ˆå»é‡ï¼‰
    primary_quotes = primary.get('Quotes', '') or ''
    secondary_quotes = secondary.get('Quotes', '') or ''
    if secondary_quotes and secondary_quotes != 'No quotes available':
        if primary_quotes == 'No quotes available':
            merged['Quotes'] = secondary_quotes
        else:
            # åˆ†å‰²å¼•è¯­å¹¶åˆå¹¶
            all_quotes = set()
            for q in primary_quotes.split('\n---\n'):
                if q.strip():
                    all_quotes.add(q.strip())
            for q in secondary_quotes.split('\n---\n'):
                if q.strip():
                    all_quotes.add(q.strip())
            merged['Quotes'] = '\n---\n'.join(list(all_quotes)[:15])  # æœ€å¤š15æ¡
    
    # åˆå¹¶åœ°ç‚¹ï¼ˆå»é‡ï¼‰
    primary_loc = primary.get('Locations', '') or ''
    secondary_loc = secondary.get('Locations', '') or ''
    if secondary_loc and secondary_loc != 'Unknown Location':
        if primary_loc == 'Unknown Location':
            merged['Locations'] = secondary_loc
        else:
            all_locs = set(primary_loc.split(', ')) | set(secondary_loc.split(', '))
            all_locs.discard('Unknown Location')
            merged['Locations'] = ', '.join(list(all_locs)[:8])
    
    # åˆå¹¶äººç‰©ï¼ˆå»é‡ï¼‰
    primary_persons = primary.get('Key_Persons', '') or ''
    secondary_persons = secondary.get('Key_Persons', '') or ''
    if secondary_persons and secondary_persons != 'Unknown':
        if primary_persons == 'Unknown':
            merged['Key_Persons'] = secondary_persons
        else:
            all_persons = set(primary_persons.split(', ')) | set(secondary_persons.split(', '))
            all_persons.discard('Unknown')
            merged['Key_Persons'] = ', '.join(list(all_persons)[:10])
    
    # åˆå¹¶ç»„ç»‡ï¼ˆå»é‡ï¼‰
    primary_orgs = primary.get('Organizations', '') or ''
    secondary_orgs = secondary.get('Organizations', '') or ''
    if secondary_orgs and secondary_orgs != 'No organizations mentioned':
        if primary_orgs == 'No organizations mentioned':
            merged['Organizations'] = secondary_orgs
        else:
            all_orgs = set(primary_orgs.split(', ')) | set(secondary_orgs.split(', '))
            all_orgs.discard('No organizations mentioned')
            merged['Organizations'] = ', '.join(list(all_orgs)[:10])
    
    # åˆå¹¶ä¸»é¢˜ï¼ˆå»é‡ï¼‰
    primary_themes = primary.get('Themes', '') or ''
    secondary_themes = secondary.get('Themes', '') or ''
    if secondary_themes and secondary_themes != 'General':
        if primary_themes == 'General':
            merged['Themes'] = secondary_themes
        else:
            all_themes = set(primary_themes.split(', ')) | set(secondary_themes.split(', '))
            all_themes.discard('General')
            merged['Themes'] = ', '.join(list(all_themes)[:10])
    
    # åˆå¹¶æ•°æ®äº‹å®ï¼ˆå»é‡ï¼‰
    primary_facts = primary.get('Data_Facts', '') or ''
    secondary_facts = secondary.get('Data_Facts', '') or ''
    if secondary_facts and secondary_facts != 'No specific data':
        if primary_facts == 'No specific data':
            merged['Data_Facts'] = secondary_facts
        else:
            all_facts = set(primary_facts.split('; ')) | set(secondary_facts.split('; '))
            all_facts.discard('No specific data')
            merged['Data_Facts'] = '; '.join(list(all_facts)[:10])
    
    # åˆå¹¶å›¾ç‰‡ï¼ˆå»é‡ï¼‰
    primary_imgs = primary.get('Images', '') or ''
    secondary_imgs = secondary.get('Images', '') or ''
    if secondary_imgs and secondary_imgs != 'No images':
        if primary_imgs == 'No images':
            merged['Images'] = secondary_imgs
        else:
            all_imgs = set(primary_imgs.split('; ')) | set(secondary_imgs.split('; '))
            all_imgs.discard('No images')
            merged['Images'] = '; '.join(list(all_imgs)[:8])
    
    # åˆå¹¶åŸæ–‡æ‘˜è¦
    primary_summary = primary.get('Article_Summary', '') or ''
    secondary_summary = secondary.get('Article_Summary', '') or ''
    if secondary_summary and not primary_summary:
        merged['Article_Summary'] = secondary_summary
    elif secondary_summary and primary_summary:
        # å¦‚æœä¸¤è¾¹éƒ½æœ‰æ‘˜è¦ï¼Œä¿ç•™è¾ƒé•¿çš„
        if len(secondary_summary) > len(primary_summary):
            merged['Article_Summary'] = secondary_summary
    
    return merged


def merge_related_news(narratives: List[Dict[str, Any]], similarity_threshold: float = 0.6) -> List[Dict[str, Any]]:
    """
    åˆå¹¶ç›¸å…³çš„æ–°é—»è®°å½•
    
    å°†æ ‡é¢˜ç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼çš„æ–°é—»åˆå¹¶æˆä¸€æ¡æ›´ä¸°å¯Œçš„è®°å½•ï¼Œ
    ä¿ç•™å¤šæ¥æºçš„å¼•ç”¨ã€æ•°æ®ã€å›¾ç‰‡ç­‰ä¿¡æ¯ã€‚
    
    Args:
        narratives: æ–°é—»è®°å½•åˆ—è¡¨
        similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0.0-1.0ï¼‰ï¼Œé»˜è®¤0.6
    
    Returns:
        åˆå¹¶åçš„æ–°é—»è®°å½•åˆ—è¡¨ï¼ˆå»é‡ä¸”å†…å®¹ä¸°å¯Œï¼‰
    """
    if not narratives:
        return []
    
    # æ ‡è®°æ¯æ¡è®°å½•æ˜¯å¦å·²è¢«åˆå¹¶
    merged_indices = set()
    result = []
    
    print(f"\nğŸ“Š å¼€å§‹åˆå¹¶ç›¸å…³æ–°é—»...")
    print(f"   åŸå§‹è®°å½•æ•°: {len(narratives)}")
    
    for i, record in enumerate(narratives):
        if i in merged_indices:
            continue
        
        # æ‰¾å‡ºæ‰€æœ‰ä¸å½“å‰è®°å½•ç›¸ä¼¼çš„è®°å½•
        similar_records = [record]
        similar_sources = [record.get('Source_Name', 'Unknown')]
        
        for j in range(i + 1, len(narratives)):
            if j in merged_indices:
                continue
            
            other_record = narratives[j]
            similarity = calculate_title_similarity(
                record.get('Title', ''),
                other_record.get('Title', '')
            )
            
            if similarity >= similarity_threshold:
                similar_records.append(other_record)
                similar_sources.append(other_record.get('Source_Name', 'Unknown'))
                merged_indices.add(j)
        
        # å¦‚æœæœ‰å¤šæ¡ç›¸ä¼¼è®°å½•ï¼Œè¿›è¡Œåˆå¹¶
        if len(similar_records) > 1:
            merged_record = similar_records[0]
            for other in similar_records[1:]:
                merged_record = merge_two_records(merged_record, other)
            
            print(f"   ğŸ”— åˆå¹¶ {len(similar_records)} æ¡ç›¸å…³æ–°é—»: {record.get('Title', '')[:50]}...")
            print(f"      æ¥æº: {', '.join(similar_sources)}")
            
            result.append(merged_record)
        else:
            result.append(record)
    
    print(f"   åˆå¹¶åè®°å½•æ•°: {len(result)}")
    print(f"   å‡å°‘é‡å¤: {len(narratives) - len(result)} æ¡")
    
    return result
