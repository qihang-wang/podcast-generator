"""
å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨
ä½¿ç”¨ APScheduler å®ç°åå°å®šæ—¶ä»»åŠ¡
"""

import logging
import os
from datetime import datetime
from contextlib import asynccontextmanager

from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger

# å…¨å±€è°ƒåº¦å™¨å®ä¾‹
scheduler = AsyncIOScheduler()


def cleanup_old_articles():
    """
    æ¸…ç†è¿‡æœŸæ–‡ç« æ•°æ®
    
    é»˜è®¤æ¸…ç†è¶…è¿‡ 7 å¤©çš„æ•°æ®ï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡ CLEANUP_DAYS é…ç½®
    """
    try:
        from podcast_generator.database import ArticleRepository
        
        repo = ArticleRepository()
        
        if not repo.is_available():
            logging.warning("âš ï¸ æ•°æ®åº“ä¸å¯ç”¨ï¼Œè·³è¿‡æ¸…ç†ä»»åŠ¡")
            return
        
        # ä»ç¯å¢ƒå˜é‡è·å–ä¿ç•™å¤©æ•°ï¼Œé»˜è®¤ 7 å¤©
        days = int(os.getenv("CLEANUP_DAYS", "7"))
        
        logging.info(f"ğŸ§¹ [å®šæ—¶ä»»åŠ¡] å¼€å§‹æ¸…ç†è¶…è¿‡ {days} å¤©çš„æ•°æ®...")
        
        # è·å–æ¸…ç†å‰çš„ç»Ÿè®¡
        stats_before = repo.get_storage_stats()
        
        # æ‰§è¡Œæ¸…ç†
        deleted = repo.cleanup_old_articles(days=days)
        
        # è·å–æ¸…ç†åçš„ç»Ÿè®¡
        stats_after = repo.get_storage_stats()
        
        logging.info(
            f"âœ… [å®šæ—¶ä»»åŠ¡] æ¸…ç†å®Œæˆï¼\n"
            f"   åˆ é™¤: {deleted} æ¡\n"
            f"   å‰©ä½™: {stats_after['total_articles']} æ¡\n"
            f"   å­˜å‚¨: {stats_after['estimated_size_mb']:.2f} MB ({stats_after['usage_percent']:.1f}%)"
        )
        
        # å¦‚æœä½¿ç”¨ç‡ä»ç„¶è¾ƒé«˜ï¼Œå‘å‡ºè­¦å‘Š
        if stats_after['warning']:
            logging.warning(stats_after['warning'])
            
    except Exception as e:
        logging.error(f"âŒ [å®šæ—¶ä»»åŠ¡] æ¸…ç†å¤±è´¥: {e}")


def setup_scheduler():
    """
    é…ç½®å®šæ—¶ä»»åŠ¡
    
    ç¯å¢ƒå˜é‡é…ç½®ï¼š
    - CLEANUP_HOUR: æ¸…ç†ä»»åŠ¡æ‰§è¡Œçš„å°æ—¶ï¼ˆé»˜è®¤ 0ï¼Œå³å‡Œæ™¨0ç‚¹ï¼‰
    - CLEANUP_MINUTE: æ¸…ç†ä»»åŠ¡æ‰§è¡Œçš„åˆ†é’Ÿï¼ˆé»˜è®¤ 0ï¼‰
    - CLEANUP_DAYS: ä¿ç•™çš„å¤©æ•°ï¼ˆé»˜è®¤ 7ï¼‰
    """
    # ä»ç¯å¢ƒå˜é‡è·å–æ‰§è¡Œæ—¶é—´ï¼Œé»˜è®¤å‡Œæ™¨ 0:00
    hour = int(os.getenv("CLEANUP_HOUR", "0"))
    minute = int(os.getenv("CLEANUP_MINUTE", "0"))
    
    # æ·»åŠ æ¸…ç†ä»»åŠ¡ - æ¯å¤©å‡Œæ™¨æ‰§è¡Œ
    scheduler.add_job(
        cleanup_old_articles,
        CronTrigger(hour=hour, minute=minute),
        id="cleanup_old_articles",
        name="æ¸…ç†è¿‡æœŸæ–‡ç« æ•°æ®",
        replace_existing=True
    )
    
    logging.info(f"ğŸ“… å®šæ—¶ä»»åŠ¡å·²é…ç½®: æ¯å¤© {hour:02d}:{minute:02d} æ‰§è¡Œæ•°æ®æ¸…ç†")


def start_scheduler():
    """å¯åŠ¨è°ƒåº¦å™¨"""
    if not scheduler.running:
        setup_scheduler()
        scheduler.start()
        logging.info("âœ… å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²å¯åŠ¨")


def stop_scheduler():
    """åœæ­¢è°ƒåº¦å™¨"""
    if scheduler.running:
        scheduler.shutdown()
        logging.info("â¹ï¸ å®šæ—¶ä»»åŠ¡è°ƒåº¦å™¨å·²åœæ­¢")


@asynccontextmanager
async def lifespan_scheduler(app):
    """
    FastAPI lifespan ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    ç”¨äºåœ¨åº”ç”¨å¯åŠ¨/å…³é—­æ—¶ç®¡ç†è°ƒåº¦å™¨
    
    ä½¿ç”¨æ–¹æ³•ï¼š
    ```python
    from podcast_generator.api.scheduler import lifespan_scheduler
    
    app = FastAPI(lifespan=lifespan_scheduler)
    ```
    """
    # å¯åŠ¨æ—¶
    start_scheduler()
    yield
    # å…³é—­æ—¶
    stop_scheduler()
