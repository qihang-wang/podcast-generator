"""
æ–‡ç« æ•°æ® API è¾…åŠ©å‡½æ•°
æŒ‰å¤©ç¼“å­˜ç­–ç•¥çš„æ ¸å¿ƒå·¥å…·å‡½æ•°
"""

import logging
import asyncio
from datetime import datetime, timedelta
from typing import List
from collections import defaultdict


# ========== ç¼“å­˜é…ç½®å¸¸é‡ ==========

# æ¯å¤©æœŸæœ›è·å–çš„æ–‡ç« æ•°é‡
EXPECTED_ARTICLES_PER_DAY = 100

# ç¼“å­˜å®Œæ•´æ€§é˜ˆå€¼ï¼ˆè‡³å°‘è¾¾åˆ°æœŸæœ›æ•°é‡çš„ 80% æ‰ç®—ç¼“å­˜å‘½ä¸­ï¼‰
CACHE_COMPLETENESS_THRESHOLD = 0.8


# ========== å¹¶å‘æ§åˆ¶ ==========

# æ¯ä¸ª (country_code, date) ç»„åˆä¸€æŠŠé”ï¼Œé˜²æ­¢é‡å¤æŸ¥è¯¢
_fetch_locks: dict[str, asyncio.Lock] = defaultdict(asyncio.Lock)


def _get_lock_key(country_code: str, date: datetime) -> str:
    """ç”Ÿæˆé”çš„ key"""
    return f"{country_code}_{date.strftime('%Y%m%d')}"


# ========== æ—¶é—´å·¥å…·å‡½æ•° ==========

def get_day_range(date: datetime) -> tuple[datetime, datetime]:
    """
    è·å–æŸä¸€å¤©çš„æ—¶é—´èŒƒå›´ (0ç‚¹åˆ°24ç‚¹)
    
    Args:
        date: æ—¥æœŸ
        
    Returns:
        (start_time, end_time) - datetime å¯¹è±¡
    """
    day_start = date.replace(hour=0, minute=0, second=0, microsecond=0)
    day_end = date.replace(hour=23, minute=59, second=59, microsecond=0)
    
    return day_start, day_end


def datetime_to_int(dt: datetime) -> int:
    """å°† datetime è½¬æ¢ä¸º YYYYMMDDHHMMSS æ ¼å¼çš„æ•´æ•°"""
    return int(dt.strftime("%Y%m%d%H%M%S"))


def get_days_list(days: int) -> List[datetime]:
    """
    è·å–éœ€è¦æŸ¥è¯¢çš„æ—¥æœŸåˆ—è¡¨
    
    Args:
        days: è·å–æœ€è¿‘ N å¤©çš„æ•°æ®
        
    Returns:
        æ—¥æœŸåˆ—è¡¨ï¼Œä»æœ€æ—©åˆ°æœ€æ–°æ’åº
        ä¾‹å¦‚ days=3ï¼Œä»Šå¤©æ˜¯1æœˆ22æ—¥ï¼Œè¿”å› [1æœˆ19æ—¥, 1æœˆ20æ—¥, 1æœˆ21æ—¥]
    """
    today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
    
    # ä»æ˜¨å¤©å¼€å§‹å¾€å‰æ¨ days å¤©
    dates = []
    for i in range(days, 0, -1):
        date = today - timedelta(days=i)
        dates.append(date)
    
    return dates


# ========== ç¼“å­˜æ£€æŸ¥ ==========

def check_day_cached(
    repo, 
    country_code: str, 
    date: datetime,
    expected_count: int = EXPECTED_ARTICLES_PER_DAY,
    threshold: float = CACHE_COMPLETENESS_THRESHOLD
) -> bool:
    """
    æ£€æŸ¥æŸä¸€å¤©çš„æ•°æ®æ˜¯å¦å·²ç¼“å­˜
    
    åˆ¤æ–­é€»è¾‘ï¼šç¼“å­˜çš„æ–‡ç« æ•°é‡è‡³å°‘è¾¾åˆ°æœŸæœ›æ•°é‡çš„æŒ‡å®šæ¯”ä¾‹ï¼ˆé»˜è®¤80%ï¼‰
    
    Args:
        repo: ArticleRepository å®ä¾‹
        country_code: å›½å®¶ä»£ç 
        date: ç›®æ ‡æ—¥æœŸ
        expected_count: æœŸæœ›çš„æ–‡ç« æ•°é‡ï¼ˆé»˜è®¤100ï¼‰
        threshold: å®Œæ•´æ€§é˜ˆå€¼ï¼ˆé»˜è®¤0.8ï¼Œå³80%ï¼‰
        
    Returns:
        True å¦‚æœç¼“å­˜æ•°æ®è¶³å¤Ÿå®Œæ•´ï¼Œå¦åˆ™ False
        
    Examples:
        - æœŸæœ› 100 æ¡ï¼Œå®é™… 100 æ¡ â†’ True (100%)
        - æœŸæœ› 100 æ¡ï¼Œå®é™… 80 æ¡ â†’ True (80%)
        - æœŸæœ› 100 æ¡ï¼Œå®é™… 79 æ¡ â†’ False (79%)
        - æœŸæœ› 100 æ¡ï¼Œå®é™… 5 æ¡ â†’ False (5%)
    """
    day_start, day_end = get_day_range(date)
    start_int = datetime_to_int(day_start)
    end_int = datetime_to_int(day_end)
    
    result = repo.query_by_country_and_time(
        country_code, start_int, end_int, page=1, page_size=1
    )
    
    actual_count = result["total"]
    min_required = int(expected_count * threshold)
    
    is_cached = actual_count >= min_required
    
    if not is_cached and actual_count > 0:
        # æœ‰éƒ¨åˆ†æ•°æ®ä½†ä¸å®Œæ•´ï¼Œæ‰“å°æ—¥å¿—
        date_str = date.strftime("%Y-%m-%d")
        logging.warning(
            f"âš ï¸ {date_str} ç¼“å­˜ä¸å®Œæ•´: {actual_count}/{expected_count} "
            f"({actual_count/expected_count*100:.0f}%), éœ€è¦ {threshold*100:.0f}%"
        )
    
    return is_cached


# ========== æ•°æ®è·å– ==========

def fetch_day_data(country_code: str, date: datetime, limit: int = EXPECTED_ARTICLES_PER_DAY):
    """
    è·å–æŸä¸€å¤©çš„æ•°æ® (ä» BigQuery) - åŒæ­¥ç‰ˆæœ¬
    
    ä½¿ç”¨ç²¾ç¡®æ—¶é—´èŒƒå›´æŸ¥è¯¢ï¼Œåªè·å–ç›®æ ‡æ—¥æœŸ 00:00:00 - 23:59:59 çš„æ•°æ®ã€‚
    
    Args:
        country_code: å›½å®¶ä»£ç 
        date: ç›®æ ‡æ—¥æœŸ
        limit: è·å–çš„æ–‡ç« æ•°é‡é™åˆ¶ï¼ˆé»˜è®¤100ï¼‰
    """
    from podcast_generator.gdelt.data_fetcher import fetch_gkg_data
    
    date_str = date.strftime("%Y-%m-%d")
    logging.info(f"ğŸ“¥ ä» BigQuery è·å– {country_code} {date_str} çš„æ•°æ® (limit={limit})...")
    
    # ä½¿ç”¨ç²¾ç¡®æ—¶é—´èŒƒå›´ï¼šç›®æ ‡æ—¥æœŸçš„ 00:00:00 åˆ° 23:59:59
    day_start, day_end = get_day_range(date)
    
    # è·å–æ•°æ®ï¼ˆä¼šè‡ªåŠ¨åŒæ­¥åˆ°æ•°æ®åº“ï¼‰
    fetch_gkg_data(
        country_code=country_code,
        start_time=day_start,
        end_time=day_end,
        limit=limit
    )
    
    logging.info(f"âœ… {date_str} æ•°æ®è·å–å®Œæˆ")


async def fetch_day_data_with_lock(
    repo,
    country_code: str, 
    date: datetime, 
    limit: int = EXPECTED_ARTICLES_PER_DAY
) -> bool:
    """
    è·å–æŸä¸€å¤©çš„æ•°æ®ï¼ˆå¸¦é”ï¼Œé˜²æ­¢å¹¶å‘é‡å¤æŸ¥è¯¢ï¼‰
    
    å¤šä¸ªè¯·æ±‚åŒæ—¶è¯·æ±‚åŒä¸€å¤©æ•°æ®æ—¶ï¼š
    - ç¬¬1ä¸ªè¯·æ±‚è·å–é”ï¼Œæ‰§è¡Œ BigQuery æŸ¥è¯¢
    - å…¶ä»–è¯·æ±‚ç­‰å¾…é”é‡Šæ”¾
    - é”é‡Šæ”¾åï¼Œå…¶ä»–è¯·æ±‚æ£€æŸ¥ç¼“å­˜å‘ç°å·²æœ‰æ•°æ®ï¼Œç›´æ¥è¿”å›
    
    Args:
        repo: ArticleRepository å®ä¾‹
        country_code: å›½å®¶ä»£ç 
        date: ç›®æ ‡æ—¥æœŸ
        limit: è·å–çš„æ–‡ç« æ•°é‡é™åˆ¶
        
    Returns:
        True å¦‚æœå®é™…æ‰§è¡Œäº†æŸ¥è¯¢ï¼ŒFalse å¦‚æœä½¿ç”¨äº†ç¼“å­˜
    """
    lock_key = _get_lock_key(country_code, date)
    date_str = date.strftime("%Y-%m-%d")
    
    async with _fetch_locks[lock_key]:
        # åŒé‡æ£€æŸ¥ï¼šè·å–é”åå†æ¬¡æ£€æŸ¥ç¼“å­˜ï¼ˆå¯èƒ½å…¶ä»–è¯·æ±‚å·²ç»å¡«å……ï¼‰
        if check_day_cached(repo, country_code, date):
            logging.debug(f"ğŸ”’ {date_str} é”åæ£€æŸ¥: ç¼“å­˜å·²ç”±å…¶ä»–è¯·æ±‚å¡«å……")
            return False
        
        # æ‰§è¡Œè€—æ—¶æŸ¥è¯¢ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥ä»£ç ï¼‰
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, fetch_day_data, country_code, date, limit)
        return True
