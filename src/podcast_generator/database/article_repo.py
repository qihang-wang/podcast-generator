"""
æ–‡ç« æ•°æ®ä»“åº“
æä¾›æ–‡ç« æ•°æ®çš„å¢åˆ æ”¹æŸ¥æ“ä½œ
"""

import logging
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timedelta

from .supabase_client import get_supabase_client, _is_supabase_configured, _is_sync_enabled


# ä¼°ç®—æ¯æ¡è®°å½•çš„å¹³å‡å¤§å°ï¼ˆå­—èŠ‚ï¼‰
# åŒ…å«ï¼šid, country_code, gkg_record_id, date_added, title, source, url, 
#       authors, persons[], organizations[], themes[], locations[], 
#       quotations[], amounts[], tone, emotion, emotion_instruction, 
#       event, images[], videos[], created_at
ESTIMATED_BYTES_PER_ARTICLE = 2048  # çº¦ 2 KB


class ArticleRepository:
    """æ–‡ç« æ•°æ®ä»“åº“"""
    
    def __init__(self):
        self._client = None
    
    @property
    def client(self):
        """è·å– Supabase å®¢æˆ·ç«¯"""
        if self._client is None:
            self._client = get_supabase_client()
        return self._client
    
    def is_available(self) -> bool:
        """æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å¯ç”¨"""
        return _is_supabase_configured() and self.client is not None
    
    def is_sync_enabled(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å¯ç”¨åŒæ­¥"""
        return _is_sync_enabled() and self.is_available()
    
    # ==================== æŸ¥è¯¢æ–¹æ³• ====================
    
    def query_by_country_and_time(
        self,
        country_code: str,
        start_time: int,
        end_time: int,
        page: int = 1,
        page_size: int = 20
    ) -> Dict[str, Any]:
        """
        æŒ‰å›½å®¶å’Œæ—¶é—´èŒƒå›´æŸ¥è¯¢æ–‡ç« 
        
        Args:
            country_code: å›½å®¶ä»£ç 
            start_time: å¼€å§‹æ—¶é—´æˆ³ (YYYYMMDDHHMMSS)
            end_time: ç»“æŸæ—¶é—´æˆ³
            page: é¡µç 
            page_size: æ¯é¡µæ•°é‡
            
        Returns:
            åŒ…å« data, total, page, page_size çš„å­—å…¸
        """
        if not self.is_available():
            return {"data": [], "total": 0, "page": page, "page_size": page_size}
        
        offset = (page - 1) * page_size
        
        result = self.client.table("articles") \
            .select("*", count="exact") \
            .eq("country_code", country_code) \
            .gte("date_added", start_time) \
            .lte("date_added", end_time) \
            .order("date_added", desc=True) \
            .range(offset, offset + page_size - 1) \
            .execute()
        
        return {
            "data": result.data,
            "total": result.count or 0,
            "page": page,
            "page_size": page_size
        }
    
    def get_time_coverage(self, country_code: str) -> Optional[Tuple[int, int]]:
        """
        è·å–æŸå›½å®¶çš„æ•°æ®æ—¶é—´è¦†ç›–èŒƒå›´
        
        Returns:
            (min_date, max_date) æˆ– Noneï¼ˆæ— æ•°æ®ï¼‰
        """
        if not self.is_available():
            return None
        
        # è·å–æœ€æ—©å’Œæœ€æ™šçš„ date_added
        result = self.client.table("articles") \
            .select("date_added") \
            .eq("country_code", country_code) \
            .order("date_added", desc=False) \
            .limit(1) \
            .execute()
        
        if not result.data:
            return None
        
        min_date = result.data[0]["date_added"]
        
        result = self.client.table("articles") \
            .select("date_added") \
            .eq("country_code", country_code) \
            .order("date_added", desc=True) \
            .limit(1) \
            .execute()
        
        max_date = result.data[0]["date_added"] if result.data else min_date
        
        return (min_date, max_date)
    
    def check_cache_coverage(
        self, 
        country_code: str, 
        start_time: int, 
        end_time: int
    ) -> Dict[str, Any]:
        """
        æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¦†ç›–è¯·æ±‚çš„æ—¶é—´èŒƒå›´
        
        Returns:
            {
                "covered": bool,
                "has_data": bool,
                "cached_range": (min, max) or None,
                "missing_before": int or None,
                "missing_after": int or None
            }
        """
        coverage = self.get_time_coverage(country_code)
        
        if coverage is None:
            return {
                "covered": False,
                "has_data": False,
                "cached_range": None,
                "missing_before": None,
                "missing_after": None
            }
        
        cached_min, cached_max = coverage
        
        # åˆ¤æ–­æ˜¯å¦å®Œå…¨è¦†ç›–
        covered = cached_min <= start_time and cached_max >= end_time
        
        # è®¡ç®—ç¼ºå¤±èŒƒå›´
        missing_before = start_time if start_time < cached_min else None
        missing_after = end_time if end_time > cached_max else None
        
        return {
            "covered": covered,
            "has_data": True,
            "cached_range": coverage,
            "missing_before": missing_before,
            "missing_after": missing_after
        }
    
    # ==================== å†™å…¥æ–¹æ³• ====================
    
    def bulk_upsert(self, articles: List[Dict[str, Any]]) -> int:
        """
        æ‰¹é‡æ’å…¥æˆ–æ›´æ–°æ–‡ç« ï¼ˆæŒ‰ gkg_record_id å»é‡ï¼‰
        
        Args:
            articles: æ–‡ç« æ•°æ®åˆ—è¡¨
            
        Returns:
            æ’å…¥/æ›´æ–°çš„è®°å½•æ•°
        """
        if not self.is_sync_enabled() or not articles:
            return 0
        
        try:
            # å…ˆæŒ‰å›½å®¶åˆ†ç»„ï¼Œå†æŒ‰æ—¶é—´é™åºæ’åºï¼ˆæ–°æ–‡ç« åœ¨å‰ï¼Œæ–¹ä¾¿åœ¨æ•°æ®åº“ä¸­æŸ¥çœ‹ï¼‰
            sorted_articles = sorted(
                articles, 
                key=lambda x: (x.get("country_code", ""), -x.get("date_added", 0))
            )
            
            result = self.client.table("articles").upsert(
                sorted_articles,
                on_conflict="gkg_record_id"
            ).execute()
            
            count = len(result.data) if result.data else 0
            logging.info(f"âœ… å·²åŒæ­¥ {count} æ¡æ•°æ®åˆ° Supabase")
            return count
        except Exception as e:
            logging.error(f"âŒ Supabase å†™å…¥å¤±è´¥: {e}")
            return 0
    
    # ==================== æ¸…ç†æ–¹æ³• ====================
    
    def cleanup_old_articles(self, days: int = 7) -> int:
        """
        æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ—§æ–‡ç« 
        
        Args:
            days: ä¿ç•™å¤©æ•°ï¼Œé»˜è®¤ 7 å¤©
            
        Returns:
            åˆ é™¤çš„è®°å½•æ•°
        """
        if not self.is_available():
            return 0
        
        cutoff = datetime.now() - timedelta(days=days)
        
        try:
            result = self.client.table("articles") \
                .delete() \
                .lt("created_at", cutoff.isoformat()) \
                .execute()
            
            count = len(result.data) if result.data else 0
            logging.info(f"ğŸ§¹ å·²æ¸…ç† {count} æ¡è¿‡æœŸæ•°æ®")
            return count
        except Exception as e:
            logging.error(f"âŒ æ¸…ç†å¤±è´¥: {e}")
            return 0
    
    # ==================== ç»Ÿè®¡æ–¹æ³• ====================
    
    def get_article_count(self, country_code: str = None) -> int:
        """è·å–æ–‡ç« æ€»æ•°"""
        if not self.is_available():
            return 0
        
        query = self.client.table("articles").select("id", count="exact")
        if country_code:
            query = query.eq("country_code", country_code)
        
        result = query.execute()
        return result.count or 0
    
    def get_storage_stats(self) -> Dict[str, Any]:
        """
        è·å–å­˜å‚¨ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            {
                "total_articles": int,          # æ–‡ç« æ€»æ•°
                "estimated_size_bytes": int,    # ä¼°ç®—å­˜å‚¨å¤§å°ï¼ˆå­—èŠ‚ï¼‰
                "estimated_size_mb": float,     # ä¼°ç®—å­˜å‚¨å¤§å°ï¼ˆMBï¼‰
                "free_tier_limit_mb": int,      # Supabase å…è´¹ç‰ˆé™åˆ¶ï¼ˆMBï¼‰
                "usage_percent": float,         # ä½¿ç”¨ç‡ç™¾åˆ†æ¯”
                "articles_by_country": dict,    # æŒ‰å›½å®¶ç»Ÿè®¡çš„æ–‡ç« æ•°
                "warning": str or None          # è­¦å‘Šä¿¡æ¯
            }
        """
        if not self.is_available():
            return {
                "total_articles": 0,
                "estimated_size_bytes": 0,
                "estimated_size_mb": 0,
                "free_tier_limit_mb": 500,
                "usage_percent": 0,
                "articles_by_country": {},
                "warning": "æ•°æ®åº“ä¸å¯ç”¨"
            }
        
        # Supabase å…è´¹ç‰ˆé™åˆ¶
        FREE_TIER_LIMIT_MB = 500
        
        # è·å–æ€»æ–‡ç« æ•°
        total_articles = self.get_article_count()
        
        # ä¼°ç®—å­˜å‚¨å¤§å°
        estimated_bytes = total_articles * ESTIMATED_BYTES_PER_ARTICLE
        estimated_mb = estimated_bytes / (1024 * 1024)
        
        # è®¡ç®—ä½¿ç”¨ç‡
        usage_percent = (estimated_mb / FREE_TIER_LIMIT_MB) * 100
        
        # æŒ‰å›½å®¶ç»Ÿè®¡
        articles_by_country = {}
        try:
            # è·å–æ‰€æœ‰å›½å®¶ä»£ç 
            result = self.client.table("articles") \
                .select("country_code") \
                .execute()
            
            if result.data:
                from collections import Counter
                country_counts = Counter(row["country_code"] for row in result.data)
                articles_by_country = dict(country_counts)
        except Exception as e:
            logging.warning(f"æŒ‰å›½å®¶ç»Ÿè®¡å¤±è´¥: {e}")
        
        # ç”Ÿæˆè­¦å‘Šä¿¡æ¯
        warning = None
        if usage_percent >= 90:
            warning = f"âš ï¸ å­˜å‚¨ä½¿ç”¨ç‡å·²è¾¾ {usage_percent:.1f}%ï¼Œå»ºè®®ç«‹å³æ¸…ç†æ•°æ®ï¼"
        elif usage_percent >= 70:
            warning = f"âš ï¸ å­˜å‚¨ä½¿ç”¨ç‡è¾ƒé«˜ ({usage_percent:.1f}%)ï¼Œå»ºè®®æ¸…ç†è¿‡æœŸæ•°æ®"
        
        return {
            "total_articles": total_articles,
            "estimated_size_bytes": estimated_bytes,
            "estimated_size_mb": round(estimated_mb, 2),
            "free_tier_limit_mb": FREE_TIER_LIMIT_MB,
            "usage_percent": round(usage_percent, 2),
            "articles_by_country": articles_by_country,
            "warning": warning
        }
