"""
æ–‡ç« æ•°æ® API è¾…åŠ©å‡½æ•°
æŒ‰å¤©ç¼“å­˜ç­–ç•¥çš„æ ¸å¿ƒå·¥å…·å‡½æ•°
"""

import logging
import asyncio
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple


# ========== ç¼“å­˜é…ç½®å¸¸é‡ ==========

# æ¯å¤©æœŸæœ›è·å–çš„æ–‡ç« æ•°é‡
EXPECTED_ARTICLES_PER_DAY = 100

# ç¼“å­˜å®Œæ•´æ€§é˜ˆå€¼ï¼ˆè‡³å°‘è¾¾åˆ°æœŸæœ›æ•°é‡çš„ 80% æ‰ç®—ç¼“å­˜å‘½ä¸­ï¼‰
CACHE_COMPLETENESS_THRESHOLD = 0.8

# å½“å¤©æ•°æ®åˆ·æ–°é—´éš”ï¼ˆç§’ï¼‰- ä¸ BigQuery æ›´æ–°å‘¨æœŸå¯¹é½
TODAY_CACHE_TTL = 15 * 60  # 15åˆ†é’Ÿ


# ========== å¹¶å‘æ§åˆ¶ ==========

# æ¯ä¸ª (country_code, date) ç»„åˆä¸€æŠŠé”ï¼Œé˜²æ­¢é‡å¤æŸ¥è¯¢
# ä½¿ç”¨æ™®é€š dictï¼Œé”åœ¨éœ€è¦æ—¶åˆ›å»º
_fetch_locks: Dict[str, asyncio.Lock] = {}
_locks_lock = asyncio.Lock()  # ç”¨äºä¿æŠ¤ _fetch_locks å­—å…¸çš„é”


async def _get_lock(key: str) -> asyncio.Lock:
    """è·å–æŒ‡å®š key çš„é”ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åˆ›å»º"""
    if key not in _fetch_locks:
        async with _locks_lock:
            # åŒé‡æ£€æŸ¥
            if key not in _fetch_locks:
                _fetch_locks[key] = asyncio.Lock()
    return _fetch_locks[key]


def _get_lock_key(country_code: str, date: datetime) -> str:
    """ç”Ÿæˆé”çš„ key"""
    return f"{country_code}_{date.strftime('%Y%m%d')}"


# ========== æ—¶é—´å·¥å…·å‡½æ•° ==========

def get_day_range(date: datetime) -> tuple[datetime, datetime]:
    """
    è·å–æŸä¸€å¤©çš„æ—¶é—´èŒƒå›´ (0ç‚¹åˆ°24ç‚¹)
    
    Args:
        date: æ—¥æœŸ
        
    Returns:
        (start_time, end_time) - datetime å¯¹è±¡
    """
    day_start = date.replace(hour=0, minute=0, second=0, microsecond=0)
    day_end = date.replace(hour=23, minute=59, second=59, microsecond=0)
    
    return day_start, day_end


def datetime_to_int(dt: datetime) -> int:
    """å°† datetime è½¬æ¢ä¸º YYYYMMDDHHMMSS æ ¼å¼çš„æ•´æ•°"""
    return int(dt.strftime("%Y%m%d%H%M%S"))


def int_to_datetime(dt_int: int) -> datetime:
    """å°† YYYYMMDDHHMMSS æ ¼å¼çš„æ•´æ•°è½¬æ¢ä¸º datetime"""
    return datetime.strptime(str(dt_int), "%Y%m%d%H%M%S")


def get_days_list(days: int) -> List[datetime]:
    """
    è·å–éœ€è¦æŸ¥è¯¢çš„æ—¥æœŸåˆ—è¡¨
    
    Args:
        days: è·å–æœ€è¿‘ N å¤©çš„æ•°æ®
        
    Returns:
        æ—¥æœŸåˆ—è¡¨ï¼Œä»æœ€æ—©åˆ°æœ€æ–°æ’åº
        ä¾‹å¦‚ days=3ï¼Œä»Šå¤©æ˜¯1æœˆ22æ—¥ï¼Œè¿”å› [1æœˆ19æ—¥, 1æœˆ20æ—¥, 1æœˆ21æ—¥]
    """
    today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
    
    # ä»æ˜¨å¤©å¼€å§‹å¾€å‰æ¨ days å¤©
    dates = []
    for i in range(days, 0, -1):
        date = today - timedelta(days=i)
        dates.append(date)
    
    return dates


# ========== ç¼“å­˜æ£€æŸ¥ ==========

def check_day_cached(
    repo, 
    country_code: str, 
    date: datetime,
    expected_count: int = EXPECTED_ARTICLES_PER_DAY,
    threshold: float = CACHE_COMPLETENESS_THRESHOLD
) -> bool:
    """
    æ£€æŸ¥æŸä¸€å¤©çš„æ•°æ®æ˜¯å¦å·²ç¼“å­˜
    
    åˆ¤æ–­é€»è¾‘ï¼šç¼“å­˜çš„æ–‡ç« æ•°é‡è‡³å°‘è¾¾åˆ°æœŸæœ›æ•°é‡çš„æŒ‡å®šæ¯”ä¾‹ï¼ˆé»˜è®¤80%ï¼‰
    
    Args:
        repo: ArticleRepository å®ä¾‹
        country_code: å›½å®¶ä»£ç 
        date: ç›®æ ‡æ—¥æœŸ
        expected_count: æœŸæœ›çš„æ–‡ç« æ•°é‡ï¼ˆé»˜è®¤100ï¼‰
        threshold: å®Œæ•´æ€§é˜ˆå€¼ï¼ˆé»˜è®¤0.8ï¼Œå³80%ï¼‰
        
    Returns:
        True å¦‚æœç¼“å­˜æ•°æ®è¶³å¤Ÿå®Œæ•´ï¼Œå¦åˆ™ False
        
    Examples:
        - æœŸæœ› 100 æ¡ï¼Œå®é™… 100 æ¡ â†’ True (100%)
        - æœŸæœ› 100 æ¡ï¼Œå®é™… 80 æ¡ â†’ True (80%)
        - æœŸæœ› 100 æ¡ï¼Œå®é™… 79 æ¡ â†’ False (79%)
        - æœŸæœ› 100 æ¡ï¼Œå®é™… 5 æ¡ â†’ False (5%)
    """
    day_start, day_end = get_day_range(date)
    start_int = datetime_to_int(day_start)
    end_int = datetime_to_int(day_end)
    
    result = repo.query_by_country_and_time(
        country_code, start_int, end_int, page=1, page_size=1
    )
    
    actual_count = result["total"]
    min_required = int(expected_count * threshold)
    
    is_cached = actual_count >= min_required
    
    if not is_cached and actual_count > 0:
        # æœ‰éƒ¨åˆ†æ•°æ®ä½†ä¸å®Œæ•´ï¼Œæ‰“å°æ—¥å¿—
        date_str = date.strftime("%Y-%m-%d")
        logging.warning(
            f"âš ï¸ {date_str} ç¼“å­˜ä¸å®Œæ•´: {actual_count}/{expected_count} "
            f"({actual_count/expected_count*100:.0f}%), éœ€è¦ {threshold*100:.0f}%"
        )
    
    return is_cached


# ========== å½“å¤©æ•°æ®å¢é‡è·å– ==========

def should_refresh_today(
    repo, 
    country_code: str
) -> Tuple[bool, Optional[datetime], Optional[datetime]]:
    """
    åˆ¤æ–­å½“å¤©æ•°æ®æ˜¯å¦éœ€è¦åˆ·æ–°
    
    é€»è¾‘ï¼š
    1. æŸ¥è¯¢æ•°æ®åº“ä¸­ä»Šå¤©è¯¥å›½å®¶çš„æœ€æ–°è®°å½•
    2. å¦‚æœæ— è®°å½• â†’ éœ€è¦å…¨é‡è·å–
    3. å¦‚æœæœ€æ–°è®°å½•è·ä»Š >= 15åˆ†é’Ÿ â†’ éœ€è¦å¢é‡è·å–
    4. å¦‚æœæœ€æ–°è®°å½•è·ä»Š < 15åˆ†é’Ÿ â†’ ä½¿ç”¨ç¼“å­˜
    
    Args:
        repo: ArticleRepository å®ä¾‹
        country_code: å›½å®¶ä»£ç 
        
    Returns:
        (need_refresh, fetch_start_time, fetch_end_time)
        - need_refresh: æ˜¯å¦éœ€è¦åˆ·æ–°
        - fetch_start_time: ä»å“ªä¸ªæ—¶é—´å¼€å§‹è·å–ï¼ˆNone è¡¨ç¤ºä» 00:00 å¼€å§‹ï¼‰
        - fetch_end_time: åˆ°å“ªä¸ªæ—¶é—´ç»“æŸï¼ˆå½“å‰æ—¶é—´ï¼‰
    """
    now = datetime.now()
    today = now.replace(hour=0, minute=0, second=0, microsecond=0)
    
    day_start, _ = get_day_range(today)
    start_int = datetime_to_int(day_start)
    end_int = datetime_to_int(now)
    
    # æŸ¥è¯¢ä»Šå¤©æœ€æ–°çš„è®°å½•
    latest_date_added = repo.get_latest_date_added(country_code, start_int, end_int)
    
    if latest_date_added is None:
        # æ— è®°å½•ï¼Œéœ€è¦å…¨é‡è·å–
        logging.info(f"ğŸ“… å½“å¤©æ— ç¼“å­˜æ•°æ®ï¼Œéœ€è¦å…¨é‡è·å– (00:00 ~ {now.strftime('%H:%M')})")
        return True, day_start, now
    
    # å°† date_added è½¬æ¢ä¸º datetime
    last_fetch_time = int_to_datetime(latest_date_added)
    minutes_since_last = (now - last_fetch_time).total_seconds() / 60
    
    if minutes_since_last >= (TODAY_CACHE_TTL / 60):
        # è¶…è¿‡15åˆ†é’Ÿï¼Œéœ€è¦å¢é‡è·å–
        logging.info(
            f"ğŸ“… å½“å¤©æœ€æ–°è®°å½•: {last_fetch_time.strftime('%H:%M')}, "
            f"å·²è¿‡ {minutes_since_last:.0f} åˆ†é’Ÿï¼Œéœ€è¦å¢é‡è·å–"
        )
        return True, last_fetch_time, now
    else:
        # 15åˆ†é’Ÿå†…ï¼Œä½¿ç”¨ç¼“å­˜
        logging.info(
            f"ğŸ“… å½“å¤©æœ€æ–°è®°å½•: {last_fetch_time.strftime('%H:%M')}, "
            f"ä»…è¿‡ {minutes_since_last:.0f} åˆ†é’Ÿï¼Œä½¿ç”¨ç¼“å­˜"
        )
        return False, None, None


def fetch_today_data(
    country_code: str, 
    start_time: datetime, 
    end_time: datetime,
    limit: int = EXPECTED_ARTICLES_PER_DAY
):
    """
    è·å–å½“å¤©æ•°æ®ï¼ˆæ”¯æŒå¢é‡ï¼‰- åŒæ­¥ç‰ˆæœ¬
    
    Args:
        country_code: å›½å®¶ä»£ç 
        start_time: å¼€å§‹æ—¶é—´
        end_time: ç»“æŸæ—¶é—´
        limit: è·å–çš„æ–‡ç« æ•°é‡é™åˆ¶
    """
    from podcast_generator.gdelt.data_fetcher import fetch_gkg_data
    
    time_range = f"{start_time.strftime('%H:%M')} ~ {end_time.strftime('%H:%M')}"
    logging.info(f"ğŸ“¥ ä» BigQuery è·å– {country_code} ä»Šå¤© {time_range} çš„æ•°æ® (limit={limit})...")
    
    # è·å–æ•°æ®ï¼ˆä¼šè‡ªåŠ¨åŒæ­¥åˆ°æ•°æ®åº“ï¼‰
    fetch_gkg_data(
        country_code=country_code,
        start_time=start_time,
        end_time=end_time,
        limit=limit
    )
    
    logging.info(f"âœ… å½“å¤©æ•°æ®è·å–å®Œæˆ")


async def fetch_today_data_with_lock(
    repo,
    country_code: str,
    limit: int = EXPECTED_ARTICLES_PER_DAY
) -> Tuple[bool, int]:
    """
    è·å–å½“å¤©æ•°æ®ï¼ˆå¸¦é”ï¼Œé˜²æ­¢å¹¶å‘é‡å¤æŸ¥è¯¢ï¼Œæ”¯æŒå¢é‡ï¼‰
    
    Args:
        repo: ArticleRepository å®ä¾‹
        country_code: å›½å®¶ä»£ç 
        limit: è·å–çš„æ–‡ç« æ•°é‡é™åˆ¶
        
    Returns:
        (fetched, incremental_count)
        - fetched: æ˜¯å¦æ‰§è¡Œäº†è·å–
        - incremental_count: å¢é‡è·å–çš„æ¡æ•°ä¼°è®¡
    """
    today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
    lock_key = _get_lock_key(country_code, today)
    
    # è·å–è¯¥ key å¯¹åº”çš„é”
    lock = await _get_lock(lock_key)
    
    async with lock:
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°
        need_refresh, start_time, end_time = should_refresh_today(repo, country_code)
        
        if not need_refresh:
            return False, 0
        
        # æ‰§è¡Œè·å–ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥ä»£ç ï¼‰
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(
            None, 
            fetch_today_data, 
            country_code, 
            start_time, 
            end_time, 
            limit
        )
        
        return True, limit  # å®é™…æ¡æ•°ç”± BigQuery è¿”å›


# ========== å†å²æ•°æ®è·å– ==========

def fetch_day_data(country_code: str, date: datetime, limit: int = EXPECTED_ARTICLES_PER_DAY):
    """
    è·å–æŸä¸€å¤©çš„æ•°æ® (ä» BigQuery) - åŒæ­¥ç‰ˆæœ¬
    
    ä½¿ç”¨ç²¾ç¡®æ—¶é—´èŒƒå›´æŸ¥è¯¢ï¼Œåªè·å–ç›®æ ‡æ—¥æœŸ 00:00:00 - 23:59:59 çš„æ•°æ®ã€‚
    
    Args:
        country_code: å›½å®¶ä»£ç 
        date: ç›®æ ‡æ—¥æœŸ
        limit: è·å–çš„æ–‡ç« æ•°é‡é™åˆ¶ï¼ˆé»˜è®¤100ï¼‰
    """
    from podcast_generator.gdelt.data_fetcher import fetch_gkg_data
    
    date_str = date.strftime("%Y-%m-%d")
    logging.info(f"ğŸ“¥ ä» BigQuery è·å– {country_code} {date_str} çš„æ•°æ® (limit={limit})...")
    
    # ä½¿ç”¨ç²¾ç¡®æ—¶é—´èŒƒå›´ï¼šç›®æ ‡æ—¥æœŸçš„ 00:00:00 åˆ° 23:59:59
    day_start, day_end = get_day_range(date)
    
    # è·å–æ•°æ®ï¼ˆä¼šè‡ªåŠ¨åŒæ­¥åˆ°æ•°æ®åº“ï¼‰
    fetch_gkg_data(
        country_code=country_code,
        start_time=day_start,
        end_time=day_end,
        limit=limit
    )
    
    logging.info(f"âœ… {date_str} æ•°æ®è·å–å®Œæˆ")


async def fetch_day_data_with_lock(
    repo,
    country_code: str, 
    date: datetime, 
    limit: int = EXPECTED_ARTICLES_PER_DAY
) -> bool:
    """
    è·å–æŸä¸€å¤©çš„æ•°æ®ï¼ˆå¸¦é”ï¼Œé˜²æ­¢å¹¶å‘é‡å¤æŸ¥è¯¢ï¼‰
    
    å¤šä¸ªè¯·æ±‚åŒæ—¶è¯·æ±‚åŒä¸€å¤©æ•°æ®æ—¶ï¼š
    - ç¬¬1ä¸ªè¯·æ±‚è·å–é”ï¼Œæ‰§è¡Œ BigQuery æŸ¥è¯¢
    - å…¶ä»–è¯·æ±‚ç­‰å¾…é”é‡Šæ”¾
    - é”é‡Šæ”¾åï¼Œå…¶ä»–è¯·æ±‚æ£€æŸ¥ç¼“å­˜å‘ç°å·²æœ‰æ•°æ®ï¼Œç›´æ¥è¿”å›
    
    Args:
        repo: ArticleRepository å®ä¾‹
        country_code: å›½å®¶ä»£ç 
        date: ç›®æ ‡æ—¥æœŸ
        limit: è·å–çš„æ–‡ç« æ•°é‡é™åˆ¶
        
    Returns:
        True å¦‚æœå®é™…æ‰§è¡Œäº†æŸ¥è¯¢ï¼ŒFalse å¦‚æœä½¿ç”¨äº†ç¼“å­˜
    """
    lock_key = _get_lock_key(country_code, date)
    date_str = date.strftime("%Y-%m-%d")
    
    # è·å–è¯¥ key å¯¹åº”çš„é”
    lock = await _get_lock(lock_key)
    
    async with lock:
        # åŒé‡æ£€æŸ¥ï¼šè·å–é”åå†æ¬¡æ£€æŸ¥ç¼“å­˜ï¼ˆå¯èƒ½å…¶ä»–è¯·æ±‚å·²ç»å¡«å……ï¼‰
        if check_day_cached(repo, country_code, date):
            logging.debug(f"ğŸ”’ {date_str} é”åæ£€æŸ¥: ç¼“å­˜å·²ç”±å…¶ä»–è¯·æ±‚å¡«å……")
            return False
        
        # æ‰§è¡Œè€—æ—¶æŸ¥è¯¢ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥ä»£ç ï¼‰
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, fetch_day_data, country_code, date, limit)
        return True
